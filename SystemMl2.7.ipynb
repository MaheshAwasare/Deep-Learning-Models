{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Assignment 4\n## Understaning scaling of linear algebra operations on Apache Spark using Apache SystemML\n\nIn this assignment we want you to understand how to scale linear algebra operations from a single machine to multiple machines, memory and CPU cores using Apache SystemML. Therefore we want you to understand how to migrate from a numpy program to a SystemML DML program. Don't worry. We will give you a lot of hints. Finally, you won't need this knowledge anyways if you are sticking to Keras only, but once you go beyond that point you'll be happy to see what's going on behind the scenes. Please make sure you run this notebook from an Apache Spark 2.3 notebook.\n\nSo the first thing we need to ensure is that we are on the latest version of SystemML, which is 1.2.0 (as of Feb. '19)\nPlease use the code block below to check if you are already on 1.2.0 or higher.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from systemml import MLContext\nml = MLContext(spark)\nml.version()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20190326060828-0000\nKERNEL_ID = 503feb82-3a39-4fbe-96a3-90a105d013bb\n"
                }, 
                {
                    "output_type": "error", 
                    "evalue": "No module named systemml", 
                    "traceback": [
                        "\u001b[0;31m\u001b[0m", 
                        "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-1-1f58af4e1d07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msystemml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMLContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mImportError\u001b[0m: No module named systemml"
                    ], 
                    "ename": "ImportError"
                }
            ], 
            "execution_count": 1
        }, 
        {
            "source": "If you are blow version 1.2.0 please execute the next two code blocks", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "!pip install systemml", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting systemml\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/94/62104cb8c526b462cd501c7319926fb81ac9a5668574a0b3407658a506ab/systemml-1.2.0.tar.gz (9.7MB)\n\u001b[K    100% |################################| 9.7MB 913kB/s eta 0:00:01\n\u001b[?25hCollecting numpy>=1.8.2 (from systemml)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/33/8ec8dcdb4ede5d453047bbdbd01916dbaccdb63e98bba60989718f5f0876/numpy-1.16.2-cp27-cp27mu-manylinux1_x86_64.whl (17.0MB)\n\u001b[K    100% |################################| 17.0MB 637kB/s eta 0:00:01\n\u001b[?25hCollecting scipy>=0.15.1 (from systemml)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/39/f1457091d0a45a84a2bd7815e2cf6bd45d4fe240728e9ed567cbb17c8abe/scipy-1.2.1-cp27-cp27mu-manylinux1_x86_64.whl (24.8MB)\n\u001b[K    100% |################################| 24.8MB 482kB/s eta 0:00:01\n\u001b[?25hCollecting pandas (from systemml)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/83/7d4008ffc2988066ff37f6a0bb6d7b60822367dcb36ba5e39aa7801fda54/pandas-0.24.2-cp27-cp27mu-manylinux1_x86_64.whl (10.1MB)\n\u001b[K    100% |################################| 10.1MB 919kB/s eta 0:00:01\n\u001b[?25hCollecting scikit-learn (from systemml)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/bb/52a01390c1dbb2c65d3072bc687271aa9ddf6964141ce7e03304820138f4/scikit_learn-0.20.3-cp27-cp27mu-manylinux1_x86_64.whl (5.5MB)\n\u001b[K    100% |################################| 5.5MB 1.2MB/s eta 0:00:01\n\u001b[?25hCollecting Pillow>=2.0.0 (from systemml)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0d/f3/421598450cb9503f4565d936860763b5af413a61009d87a5ab1e34139672/Pillow-5.4.1-cp27-cp27mu-manylinux1_x86_64.whl (2.0MB)\n\u001b[K    100% |################################| 2.0MB 2.0MB/s eta 0:00:01\n\u001b[?25hCollecting pytz>=2011k (from pandas->systemml)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/28/1d3920e4d1d50b19bc5d24398a7cd85cc7b9a75a490570d5a30c57622d34/pytz-2018.9-py2.py3-none-any.whl (510kB)\n\u001b[K    100% |################################| 512kB 2.6MB/s eta 0:00:01\n\u001b[?25hCollecting python-dateutil>=2.5.0 (from pandas->systemml)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n\u001b[K    100% |################################| 235kB 2.5MB/s eta 0:00:01\n\u001b[?25hCollecting six>=1.5 (from python-dateutil>=2.5.0->pandas->systemml)\n  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\nBuilding wheels for collected packages: systemml\n  Running setup.py bdist_wheel for systemml ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/spark/shared/.cache/pip/wheels/cf/07/79/b3ed6f12afe06b2ab55d60dcfd62e66240f5d8c6088a518177\nSuccessfully built systemml\n\u001b[31mtensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\n\u001b[31mpyspark 2.3.0 requires py4j==0.10.6, which is not installed.\u001b[0m\nInstalling collected packages: numpy, scipy, pytz, six, python-dateutil, pandas, scikit-learn, Pillow, systemml\nSuccessfully installed Pillow-5.4.1 numpy-1.16.2 pandas-0.24.2 python-dateutil-2.8.0 pytz-2018.9 scikit-learn-0.20.3 scipy-1.2.1 six-1.12.0 systemml-1.2.0\n"
                }
            ], 
            "execution_count": 2
        }, 
        {
            "source": "Now we need to create two sym links that the newest version is picket up - this is a workaround and will be removed soon", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from systemml import MLContext\nml = MLContext(spark)\nml.version()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "u'0.14.0-incubating'"
                    }, 
                    "execution_count": 3, 
                    "metadata": {}
                }
            ], 
            "execution_count": 3
        }, 
        {
            "source": "!ln -s -f ~/user-libs/python3/systemml/systemml-java/systemml-1.2.0-extra.jar ~/user-libs/spark2/systemml-1.2.0-extra.jar\n!ln -s -f ~/user-libs/python3/systemml/systemml-java/systemml-1.2.0.jar ~/user-libs/spark2/systemml-1.2.0.jar", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 4
        }, 
        {
            "source": "Now please restart the kernel and make sure the version is correct", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from systemml import MLContext\nml = MLContext(spark)\nml.version()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "u'0.14.0-incubating'"
                    }, 
                    "execution_count": 5, 
                    "metadata": {}
                }
            ], 
            "execution_count": 5
        }, 
        {
            "source": "Congratulations, if you see version 1.2.0 or higher, please continue with the notebook...", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "from systemml import MLContext, dml\nimport numpy as np\nimport time", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 6
        }, 
        {
            "source": "Then we create an MLContext to interface with Apache SystemML. Note that we pass a SparkSession object as parameter so SystemML now knows how to talk to the Apache Spark cluster", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "ml = MLContext(spark)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 7
        }, 
        {
            "source": "Now we create some large random matrices to have numpy and SystemML crunch on it", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "u = np.random.rand(1000,10000)\ns = np.random.rand(10000,1000)\nw = np.random.rand(1000,1000)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 8
        }, 
        {
            "source": "Now we implement a short one-liner to define a very simple linear algebra operation\n\nIn case you are unfamiliar with matrxi-matrix multiplication: https://en.wikipedia.org/wiki/Matrix_multiplication\n\nsum(U' * (W . (U * S)))\n\n\n| Legend        |            |   \n| ------------- |-------------| \n| '      | transpose of a matrix | \n| * | matrix-matrix multiplication      |  \n| . | scalar multiplication      |   \n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "start = time.time()\nres = np.sum(u.T.dot(w * u.dot(s)))\nprint (time.time()-start)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "1.4122338295\n"
                }
            ], 
            "execution_count": 9
        }, 
        {
            "source": "As you can see this executes perfectly fine. Note that this is even a very efficient execution because numpy uses a C/C++ backend which is known for it's performance. But what happens if U, S or W get such big that the available main memory cannot cope with it? Let's give it a try:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#u = np.random.rand(10000,100000)\n#s = np.random.rand(100000,10000)\n#w = np.random.rand(10000,10000)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "After a short while you should see a memory error. This is because the operating system process was not able to allocate enough memory for storing the numpy array on the heap. Now it's time to re-implement the very same operations as DML in SystemML, and this is your task. Just replace all ###your_code_goes_here sections with proper code, please consider the following table which contains all DML syntax you need:\n\n| Syntax        |            |   \n| ------------- |-------------| \n| t(M)      | transpose of a matrix, where M is the matrix | \n| %*% | matrix-matrix multiplication      |  \n| * | scalar multiplication      |   \n\n## Task", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "In order to show you the advantage of SystemML over numpy we've blown up the sizes of the matrices. Unfortunately, on a 1-2 worker Spark cluster it takes quite some time to complete. Therefore we've stripped down the example to smaller matrices below, but we've kept the code, just in case you are curious to check it out. But you might want to use some more workers which you easily can configure in the environment settings of the project within Watson Studio. Just be aware that you're currently limited to free 50 capacity unit hours per month wich are consumed by the additional workers.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "script = \"\"\"\nU = rand(rows=1000,cols=10000)\nS = rand(rows=10000,cols=1000)\nW = rand(rows=1000,cols=1000)\nres = sum(U %*% (W * (U * S)))\n\"\"\"", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 12
        }, 
        {
            "source": "To get consistent results we switch from a random matrix initialization to something deterministic", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "#prog = dml(script).input('U', u).input('S', s).input('W', w).output('res')\nprog = dml(script).output('res')\nres = ml.execute(prog).get('res')\nprint(res)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "error", 
                    "evalue": "'JavaPackage' object is not callable", 
                    "traceback": [
                        "\u001b[0;31m\u001b[0m", 
                        "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-14-5ac0c3e6368d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#prog = dml(script).input('U', u).input('S', s).input('W', w).output('res')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'res'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'res'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/home/spark/shared/user-libs/python2/systemml/mlcontext.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, script)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mglobal\u001b[0m \u001b[0mdefault_jvm_stdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_jvm_stdout_parallel_flush\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefault_jvm_stdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mjvm_stdout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel_flush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_jvm_stdout_parallel_flush\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mMLResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript_java\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/home/spark/shared/user-libs/python2/systemml/classloader.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parallel_flush)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \"\"\"\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel_flush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_spark_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msysml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUtils\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_flush\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel_flush\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_stdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mTypeError\u001b[0m: 'JavaPackage' object is not callable"
                    ], 
                    "ename": "TypeError"
                }
            ], 
            "execution_count": 14
        }, 
        {
            "source": "If everything runs fine you should get *6244089899151.321* as result. Feel free to submit your DML script to the grader now!\n\n### Submission", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "!rm -f rklib.py\n!wget https://raw.githubusercontent.com/romeokienzler/developerWorks/master/coursera/ai/rklib.py", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "--2019-03-26 06:16:34--  https://raw.githubusercontent.com/romeokienzler/developerWorks/master/coursera/ai/rklib.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2289 (2.2K) [text/plain]\nSaving to: 'rklib.py'\n\nrklib.py            100%[===================>]   2.24K  --.-KB/s    in 0s      \n\n2019-03-26 06:16:34 (48.4 MB/s) - 'rklib.py' saved [2289/2289]\n\n"
                }
            ], 
            "execution_count": 15
        }, 
        {
            "source": "from rklib import submit\nkey = \"esRk7vn-Eeej-BLTuYzd0g\"\n\n\nemail = \"maheshawasare@gmail.com\"", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 17
        }, 
        {
            "source": "part = \"fUxc8\"\nsecret = \"a3bHohIUaFqADBBe\"\nsubmit(email, secret, key, part, [part], script)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Submission successful, please check on the coursera grader page for the status\n-------------------------\n{\"elements\":[{\"itemId\":\"P1p3F\",\"id\":\"tE4j0qhMEeecqgpT6QjMdA~P1p3F~xyXjGE-OEemGdxI2kcdvuA\",\"courseId\":\"tE4j0qhMEeecqgpT6QjMdA\"}],\"paging\":{},\"linked\":{}}\n-------------------------\n"
                }
            ], 
            "execution_count": 18
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2.7 with Spark", 
            "name": "python2", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.14", 
            "name": "python", 
            "pygments_lexer": "ipython2", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}